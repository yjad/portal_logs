{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import os\n",
    "# import lxml\n",
    "# import DB as db"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects= (66, 67, 68, 69)\n",
    "# files = ('Results-66.txt', 'Results-67.txt', 'Results-68.txt', 'Results-69.txt')\n",
    "dir = r\"C:\\Users\\yahia\\OneDrive - Data and Transaction Services\\Projects\\Realestate Reservation Portal\\5- Operation\\Incident reports\\change land-no\\checksum\"\n",
    "\n",
    "lst = []\n",
    "for p in projects:\n",
    "\n",
    "    fpath = os.path.join(dir, f\"Results-{p}.txt\") \n",
    "    with open(fpath, 'rt') as f:\n",
    "        while(True):\n",
    "            line = f.readline()\n",
    "            if not line: break\n",
    "            if line[:5] in ('-----', '     '): continue\n",
    "            NID = line[25:39]\n",
    "            land_id = line[51:56]\n",
    "            res_no = line[79:93]\n",
    "            valid = line[98:106].strip()\n",
    "            rec = [p, NID, land_id, res_no, valid]\n",
    "            lst.append(rec)\n",
    "\n",
    "df = pd.DataFrame(data=lst, columns=['project', 'NID', 'land_id', 'reservation_no', 'valid'])\n",
    "df.to_csv('./out/checksum.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame()\n",
    "df1['NID'] = df.iloc[:,0].str[25:41]\n",
    "df1['land_id'] = df.iloc[:,1].str[10:16]\n",
    "df1['res_no'] = df.iloc[:,2].str[22:35]\n",
    "df1['valid'] = df.iloc[:,2].str[40:50]\n",
    "df1.loc[df1.NID.str.startswith('---')]\n",
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dblog_csv_fn = r\"C:\\Yahia\\Python\\portal_logs\\out\\dblog_from-to_db_log.csv\"\n",
    "# df = pd.read_csv(dblog_csv_fn, parse_dates=True, usecols=['tmstamp', 'query','params','proc_tbl'])\n",
    "df = pd.read_csv(dblog_csv_fn, parse_dates=True, usecols=['params','proc_tbl'])\n",
    "proc_name = 'reserveLand'\n",
    "tbl = df.loc[df.proc_tbl == proc_name]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tbl.params.str.split(',')\n",
    "# t.apply(lambda x: x[2])\n",
    "t.apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparams = len(tbl.iloc[0,1].split(','))\n",
    "df = pd.DataFrame()\n",
    "t = tbl.params.str.split(',')\n",
    "for i in range(nparams) :\n",
    "    df[f\"P{i+1}\"] = t.apply(lambda x: x[i])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"Gov\":\"القاهرة\",\"City\":\"القاهرة الجديدة\",\"Region\":\"نزهة التجمع الثالث بمنطقة المستقبل (3)\",\"District\":\"null\",\"Sub_District\":\"null\",\"Floor_No\":\"0\",\"building_no\":\"2\",\"Unit_No\":\"15\",\"Unit_Model\":\"A\",\"Unit_ID\":\"118744\",\"checksum\":\"01AE4AA44C9C78B81EFC0443D02AC43C687F023ECCB8A07631FEC86258B50CE7F6\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "fn = r\"C:\\Users\\yahia\\Downloads\\server.log.2022-12-28.tar.gz\"\n",
    "\n",
    "file_name = None\n",
    "file_obj = fn\n",
    "with tarfile.open(name  = fn, fileobj = file_obj, mode = \"r:gz\") as tar:\n",
    "    for member in tar.getmembers():\n",
    "        f=tar.extractfile(member)\n",
    "        for f in zfiles:\n",
    "        line_no = 0\n",
    "        # print (fname)\n",
    "        while True:\n",
    "            txt = f.readline()\n",
    "            # print (len(txt), txt)\n",
    "            if not txt: break # end of file\n",
    "            line_no += 1\n",
    "\n",
    "            # if line_no > 10000: break\n",
    "            # if line_no < 100000000: continue\n",
    "            # if line_no % 10000 == 0: print (line_no)\n",
    "            if line_no % 40000 == 0: print (line_no)\n",
    "            \n",
    "            txt = txt.decode('utf-8')\n",
    "            log_type = txt[24:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "fn = r\"C:\\Users\\yahia\\OneDrive - Data and Transaction Services\\Python-data\\PortalLogs\\DB-summary\\log summary-2022-12-26.zip\"\n",
    "df = pd.read_csv(fn, compression='zip', date_parser='timestamp', infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x= pd.to_datetime(df.timestamp).dt.date\n",
    "# df1 = pd.concat([df,x], axis=1)\n",
    "df1=df.copy()\n",
    "df1.timestamp = pd.to_datetime(df.timestamp).dt.date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.groupby('timestamp').count().max().index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fn = r\"./out/xx.csv\"\n",
    "df = pd.read_csv(fn)    #, compression='zip')#, date_parser='timestamp', infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['res_date'] = df.land_application_date.apply(lambda x: x[:10])\n",
    "df1= df[['project_id', 'land_application_date']].groupby(['project_id']).count()\n",
    "df1 = df1.rename({'land_application_date':'Count'}, axis=1).reset_index().set_index('project_id')\n",
    "df2 = db.query_to_pd('project')\n",
    "df3 = pd.concat([df2, df1],axis=1 )\n",
    "df3.dropna(subset=['Count'], inplace=True)\n",
    "df3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 3    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fn = r\"C:\\Users\\yahia\\Downloads\\18-06.txt\"\n",
    "fn = r\"C:\\Users\\yahia\\Downloads\\server.log.2023-01-22\"\n",
    "out_lst = []\n",
    "with  open (fn, 'rt', encoding='utf8') as f:\n",
    "    line_no = 1\n",
    "\n",
    "    while True:\n",
    "        txt = f.readline()\n",
    "        if not txt:\n",
    "            break\n",
    "\n",
    "        # if txt.find('WebRequestInterceptor') != -1: continue\n",
    "        # x = txt.find(\"[eg.intercom.hdb.rer.web.controllers.advice.ControllerExceptionHandler]\")\n",
    "        # if x == -1:\n",
    "            # line_no +=1\n",
    "            # continue\n",
    "        if txt[30:101] != \"[eg.intercom.hdb.rer.web.controllers.advice.ControllerExceptionHandler]\":\n",
    "            # print (txt[101:171])\n",
    "            continue\n",
    "        \n",
    "        lst = txt[122:].rstrip().split(': ')\n",
    "        l = len(lst)\n",
    "        try:\n",
    "            if l ==1:\n",
    "                exception_type = lst[0].lstrip()\n",
    "                exception_desc = ''\n",
    "            elif l == 2:\n",
    "                exception_type = lst[1]\n",
    "                exception_desc = ''\n",
    "            else:\n",
    "                exception_type = lst[1]\n",
    "                exception_desc = lst[2]\n",
    "        except:\n",
    "            print (line_no, \":\", len(lst) , \" ************\\n\", txt )\n",
    "        x = exception_desc.find('org.springframework')\n",
    "        if x != -1: # found\n",
    "            y = exception_desc[x:].find(':')\n",
    "            exception_desc_type = exception_desc[x:y].split('.')[-1]\n",
    "        else:\n",
    "            exception_desc_type = ''\n",
    "        out_lst.append([line_no, exception_type, exception_desc_type, exception_desc])\n",
    "        line_no +=1\n",
    "        # if line_no > 20000: break\n",
    "        if line_no % 1000 == 0: print (line_no)\n",
    "df = pd.DataFrame(out_lst, columns=['line_no', 'exception_type', 'exception_desc_type', 'exception_desc'])\n",
    "# x =df.pivot_table(columns=  'excption_type', index='excption_desc', values = 'line_no', aggfunc='count', margins=True, fill_value=0)\n",
    "x =df.pivot_table(index= ['exception_type',  'exception_desc_type', 'exception_desc'], values = 'line_no', aggfunc='count', margins=True, fill_value=0)\n",
    "x.to_csv('./out/xx1.csv', index=True)\n",
    "# x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fn = r\"C:\\Users\\yahia\\Downloads\\18-06.txt\"\n",
    "fn = r\"C:\\Users\\yahia\\Downloads\\server.log.2023-01-22\"\n",
    "out_lst = []\n",
    "with  open (fn, 'rt', encoding='utf8') as f:\n",
    "    line_no = 1\n",
    "\n",
    "    while True:\n",
    "        txt = f.readline()\n",
    "        if not txt:\n",
    "            break\n",
    "        # line_no += 1\n",
    "        if line_no > 2000: break\n",
    "        # if line_no % 1000000 == 0: print (line_no)\n",
    "        if txt[24:29] != 'ERROR': \n",
    "            continue\n",
    "        x = txt.find(']', 32)\n",
    "        # print (x, ':', txt)\n",
    "        log_type = txt[30:x+1] # skip (default task-9999)\n",
    "        log_desc = txt[x+22:].lstrip()\n",
    "        if log_type == '[eg.intercom.hdb.rer.web.config.WebRequestInterceptor]': continue\n",
    "        if log_type == '[org.thymeleaf.TemplateEngine]': \n",
    "            log_desc = log_desc[31:].lstrip()    # skip task-id in [THYMELEAF][default task-10430]\n",
    "        x = log_desc.find('org.springframework.')\n",
    "        if x != -1: # found\n",
    "            y = log_desc[x:].find(':')\n",
    "            log_desc_type = log_desc[x:x+y].split('.')[-1]\n",
    "            print (y, log_desc[x:x+y+1], \"***\", log_desc_type)\n",
    "        else:\n",
    "            log_desc_type = ''\n",
    "        out_lst.append([line_no, log_type, log_desc_type, log_desc])\n",
    "        # print ([line_no, log_type, txt[x+2:]])\n",
    "        out_lst.append([line_no, log_type, log_desc])\n",
    "        \n",
    "df = pd.DataFrame(out_lst, columns=['line_no', 'log_type', 'log_desc_type', 'log_desc'])\n",
    "# x =df.pivot_table(columns=  'excption_type', index='excption_desc', values = 'line_no', aggfunc='count', margins=True, fill_value=0)\n",
    "x =df.pivot_table(index= ['log_type', 'log_desc_type', 'log_desc'], values = 'line_no', aggfunc='count', margins=True, fill_value=0)\n",
    "# df.to_csv('./out/xx1.csv', index=True)\n",
    "x.to_csv('./out/xx.csv', index=True)\n",
    "# x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parse engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parse_tech_log():\n",
    "    fn = r\"C:\\Users\\yahia\\Downloads\\server.log.2023-01-22\"\n",
    "    out_lst = []\n",
    "    with  open (fn, 'rt', encoding='utf8') as f:\n",
    "        line_no = 1\n",
    "\n",
    "        while True:\n",
    "            txt = f.readline()\n",
    "            if not txt:\n",
    "                break\n",
    "            # line_no += 1\n",
    "            if line_no > 2000: break\n",
    "            # if line_no % 1000000 == 0: print (line_no)\n",
    "            if txt[24:29] != 'ERROR': \n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tokens = pd.DataFrame(columns = ['token','categ','prio','desc', 'func'], \n",
    "data=[\n",
    "['ERROR [eg.intercom.hdb.rer.web.controllers.advice.ControllerExceptionHandler]', 'tech', 0, 'Exception', 'error_exception_handler'],\n",
    "['ERROR [org.thymeleaf.TemplateEngine]', 'tech', 1, 'thymeleaf', 'thymeleaf_log_handler'],\n",
    "['ERROR [io.undertow.request]', 'tech', 1, 'TemplateInputException', 'undertow_log_handler'],\n",
    "['ERROR [eg.intercom.hdb.rer.web.config.WebRequestInterceptor]', 'user', 1, 'NID data', 'WebRequestInterceptor'],\n",
    "['ERROR [eg.intercom.hdb.rer.web.config.security.CustomUsernamePasswordAuthenticationFilter]', 'user', 1, 'Authentication', 'authetication_error_handler'],\n",
    "])\n",
    "x = \"\"\"\n",
    "# ['ControllerExceptionHandler','tech',9,'ControllerExceptionHandler'],\n",
    "['userLocked','user',0,None, None],\n",
    "['MailSendException','user',1,'Email quota exception', None],\n",
    "['UserNotFound','user',2,None], None,\n",
    "['isReCAPTCHAValid','user',3,None, None],\n",
    "['changeUserPassword','user',4,None, None],\n",
    "['ResourceAccessException','user',4,'sending SMS', None],\n",
    "['AuthenticationFailedException','user',4,'Too many login attempts', None],\n",
    "['HttpRequestMethodNotSupportedException','tech',4,None, None],\n",
    "['TemplateInputException','tech',5,None, None],\n",
    "['IllegalStateException','tech',6,'ISE', None],\n",
    "['[stderr], (default task-,tech',7,'stderr', None],\n",
    "['Exception processing template','tech',8,'EPT', None],\n",
    "['ControllerExceptionHandler','tech',9,'ControllerExceptionHandler', None],\n",
    "['[stderr], (pool-','tech',10,'stderr', None],\n",
    "['mimeType','tech',11,'java.lang', None],\n",
    "['java.lang.','tech',12,'mimeType', None],\n",
    "['java.base','tech',13,'java.base', None],\n",
    "['SMSStatusUpdateJobScheduler','tech',14,'SMSStatusUpdateJobScheduler', None],\n",
    "['.jboss.','tech',15,'jboss', None],\n",
    "['org.wildfly.','tech', 16, 'Wildfly', None, None],\n",
    "['org.springframework.', 'tech', 17, 'SpringFramework', None],\n",
    "['io.undertow.', 'tech', 18, 'Undertow Web Server', None],\n",
    "['javax.', 'tech', 19, 'javax', None],\n",
    "['jdk.internal.reflect.GeneratedMethodAccessor', 'tech', 19, 'jdk', None],\n",
    "['eg.intercom.hdb.rer.', 'tech', 19, 'Intercom', None],\n",
    "['io.opentracing.contrib.jaxrs2.server.SpanFinishingFilter', 'tech', 19, 'jaxrs2', None],\n",
    "['deployment.hdb-rer-admin', 'tech', 19, 'Admin CSV', None],\n",
    "['java.net.UnknownHostException: www.google.com', 'tech', 19, 'UnknownHostException', None],\n",
    "])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tokens_data import Tokens\n",
    "\n",
    "def parse_tech_log_line(line_no, txt):\n",
    "    for token in Tokens.itertuples():\n",
    "        p = txt.find(token.token) \n",
    "        if p != -1 :  # found\n",
    "            # print (token, \"------->\", token) \n",
    "            # error_token = token.token\n",
    "            if token.func:\n",
    "                l = len(token.token)\n",
    "                match (token.func):\n",
    "                    case 'error_exception_handler':\n",
    "                        log_desc_type, log_desc = error_exception_handler(line_no, txt[p+l:])\n",
    "                        return token.token, log_desc_type, log_desc\n",
    "                    case 'thymeleaf_log_handler':\n",
    "                        return token.token, token.desc, ''\n",
    "                    case 'undertow_log_handler':\n",
    "                        return token.token, token.desc, ''\n",
    "                    case 'WebRequestInterceptor':\n",
    "                        return token.token, token.desc, ''\n",
    "                    case 'authetication_error_handler':\n",
    "                        return token.token, token.desc, ''\n",
    "                \n",
    "            if pd.isnull(token.desc):\n",
    "                error_token = token.token\n",
    "            else:\n",
    "                error_token = token.desc\n",
    "            error_categ = token.categ\n",
    "\n",
    "            # txt= None   # error text is not needed in this case\n",
    "            classified = True\n",
    "            break    \n",
    "    return 'Unclassified', txt, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_exception_handler(line_no, txt):\n",
    "    # found = 'ERROR [eg.intercom.hdb.rer.web.controllers.advice.ControllerExceptionHandler]'\n",
    "    # Handling exception of type: org.springframework.web.HttpRequestMethodNotSupportedException: Request method 'GET' not supported\n",
    "    lst = txt.split(': ')\n",
    "    l = len(lst)\n",
    "    try:\n",
    "        if l ==1:   #(default task-7437) handling NotFoundException\"\n",
    "            exception_type = lst[0].split()[-1] \n",
    "            exception_desc = ''\n",
    "        elif l == 2:\n",
    "            # (default task-7604) Handling exception of type: java.lang.Exception\n",
    "            exception_type = \"Java Lang\"     #lst[0]\n",
    "            exception_desc = lst[1].rstrip()\n",
    "        else:\n",
    "            exception_type = lst[1].split('.')[-1]\n",
    "            exception_desc = lst[2].rstrip()\n",
    "    except Exception as e:\n",
    "        print (line_no, \":\", len(lst) , f\", Exception: {e}\\n\", txt )\n",
    "\n",
    "    # print (line_no, l,  exception_type, exception_desc, '\\n', txt)\n",
    "    return exception_type, exception_desc\n",
    "    \n",
    "\n",
    "def thymeleaf_log_handler(txt):\n",
    "    return 0, 0\n",
    "    # x=0\n",
    "    # log_type = txt[30:x+1] # skip (default task-9999)\n",
    "    # log_desc = txt[x+22:].lstrip()\n",
    "    # if log_type == '[org.thymeleaf.TemplateEngine]': \n",
    "    #     log_desc = log_desc[31:].lstrip()    # skip task-id in [THYMELEAF][default task-10430]\n",
    "    # x = log_desc.find('org.springframework.')\n",
    "    # if x != -1: # found\n",
    "    #     y = log_desc[x:].find(':')\n",
    "    #     log_desc_type = log_desc[x:x+y].split('.')[-1]\n",
    "    #     print (y, log_desc[x:x+y+1], \"***\", log_desc_type)\n",
    "    # else:\n",
    "    #     log_desc_type = ''\n",
    "    # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fn = r\"C:\\Users\\yahia\\Downloads\\18-06.txt\"\n",
    "fn = r\"C:\\Users\\yahia\\Downloads\\server.log.2023-01-22\"\n",
    "out_lst = []\n",
    "with  open (fn, 'rt', encoding='utf8') as f:\n",
    "    line_no = 1\n",
    "\n",
    "    while True:\n",
    "        txt = f.readline()\n",
    "        if not txt:\n",
    "            break\n",
    "        line_no += 1\n",
    "        # if line_no > 2000000: break\n",
    "        # if line_no % 1000000 == 0: print (line_no)\n",
    "        if txt[24:29] != 'ERROR': \n",
    "            continue\n",
    "        log_type, log_desc_type, log_desc=  parse_tech_log_line(line_no, txt)\n",
    "        out_lst.append([line_no, log_type, log_desc_type, log_desc])\n",
    "        \n",
    "df = pd.DataFrame(out_lst, columns=['line_no', 'log_type', 'log_desc_type', 'log_desc'])\n",
    "df.to_csv('./out/xx1.csv', index=False)\n",
    "# x =df.pivot_table(columns=  'excption_type', index='excption_desc', values = 'line_no', aggfunc='count', margins=True, fill_value=0)\n",
    "x =df.pivot_table(index= ['log_type', 'log_desc_type', 'log_desc'], values = 'line_no', aggfunc='count', margins=True, fill_value=0)\n",
    "x.to_csv('./out/xx.csv', index=True)\n",
    "# x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test exception pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = r\"C:\\Users\\yahia\\OneDrive - Data and Transaction Services\\Python-data\\PortalLogs\\summary\\log summary-2023-01-22.zip\"\n",
    "df = pd.read_csv(fn, compression='zip', low_memory=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "df.error_line.fillna(' ', inplace = True)\n",
    "df.loc[df.categ == 'tech'].pivot_table(index= ['service', 'error_line'], values = 'line_no', columns = 'token', aggfunc='count', fill_value=0)#.to_csv('./out/xxx.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.loc[df.categ == 'tech']\n",
    "df1.token.unique()\n",
    "# df1.service.unique()\n",
    "df1[['token', 'log_date']].groupby('token').aggregate('count')\n",
    "# df1.loc[df1.token == 'Exception', ['service', 'log_date', 'error_line']].groupby(['service', 'error_line']).aggregate('count').sort_values('log_date', ascending=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test pandas 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn = r\"C:\\Users\\yahia\\OneDrive - Data and Transaction Services\\Python-data\\PortalLogs\\summary\\log summary-2023-04-03.zip\"\n",
    "# fn = r\"C:\\Users\\yahia\\OneDrive - Data and Transaction Services\\Python-data\\PortalLogs\\logs\\server.log.2023-02-23.zip\"\n",
    "fn= r\"C:\\Users\\yahia\\OneDrive - Data and Transaction Services\\Python-data\\PortalLogs\\summary\\log summary-2023-02-23-YJ-DELL.zip\"\n",
    "# %timeit df= pd.read_csv(fn)\n",
    "df= pd.read_csv(fn, dtype_backend = 'pyarrow', low_memory=False)\n",
    "# pd.options.mode.dtype_backend = 'pyarrow'\n",
    "\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_fn = r\"C:\\Users\\yahia\\OneDrive - Data and Transaction Services\\Projects\\Realestate Reservation Portal\\5- Operation\\Incident reports\\Reservation with status N\\Copy of mpc_pro.xls\"\n",
    "pro_2_fn = r\"C:\\Users\\yahia\\OneDrive - Data and Transaction Services\\Projects\\Realestate Reservation Portal\\5- Operation\\Incident reports\\Reservation with status N\\Copy of soc_pro.xls\"\n",
    "data_types = {'الرقم القومى للزوج / ': 'string[pyarrow]', \n",
    "              'الرقم الأرضى': 'string[pyarrow]',\n",
    "             'الرقم المحمول': 'string[pyarrow]',\n",
    "             'الرقم القومى': 'string[pyarrow]',\n",
    "             'رقم الأستمارة': 'string[pyarrow]'}\n",
    "rdf_1= pd.read_excel(proj_fn, dtype_backend = 'pyarrow', skiprows=2 , dtype=data_types)\n",
    "rdf_2= pd.read_excel(pro_2_fn, dtype_backend = 'pyarrow', skiprows=0 , dtype=data_types)\n",
    "rdf =  pd.concat([rdf_1, rdf_2])\n",
    "rdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip = df.query(\"token == 'confirmLandReservation True'\")[['NID', 'IP_address', 'country', 'log_date']]\n",
    "ip.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"token == 'confirmLandReservation True' and NID == '25006192300285'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.merge(ip, how='left',right_on= 'NID', left_on=rdf.columns[15]).to_excel('./out/reservatio_with_N.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "100  1\n",
       "122  2\n",
       "233  3\n",
       "222  4\n",
       "333  5\n",
       "444  6\n",
       "555  7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst=[1,2,3,4,5,6,7]\n",
    "li = [100,122,233,222,333,444, 555]\n",
    "\n",
    "pd.DataFrame(lst, index=li)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
